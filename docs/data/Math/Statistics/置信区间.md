---
show: true
cover: math4.jpg
collection: statistics
collectionOrder: 6
tags:
  - math
  - statistics
---

# 置信区间 confidence intervals
使用样本量抽样分布构建置信区间，以利用样本量「最好地」估计的参数。置信区间的目的一般是提供总体中的聚合值（的估算值），而非针对一个特定的个体的估算（机器学习则可对每个单独数据点预测结果，如**线性回归**和**逻辑回归**）

样本平均数的置信区间可理解为**可信度**为 `95%`，**总体平均数落在你发现的范围内** 。

注意根据构建置信区间的目的和每端删除的百分比，百分比和参数都会发生变化。

## 构建置信区间

* 样本容量较大，最终相似性越高，适合自助法。
* 样本容量较小，不适合自助法，使用传统的假设检验方法，但可以产生区间不正确的设想（因为可能会因为无法较好地展现整个总体，所以产生错误结果）。

### 假设检验构建方法
传统的置信区间构建方法基于假设检验：
* `T-Test` 单样本T检验
* `Two Sample T-Test` 双样本T检验
* `Paired T-Test` 配对T检验（常用于将个体与自己比较）
* `Z-Test` Z检验
* `CHI-Squared Test` 卡方检验
* `F-Test` F检验

注意：
* 置信区间和假设检验实际上完成同样的事情
* 一个对于传统方法有根据但是具有潜在偏见的看法是，这些方法在现代统计学计算中不再需要。这些方法在未来计算中重要性不断降低。然而，应该对这些传统的假设检验技巧研究几百次，参见对应的[假设检验文档](https://stattrek.com/hypothesis-test/hypothesis-testing.aspx) `Hypothesis tests`

### 自助法/自展法 bootstrap 构建方法
基于**大数定理**和**中心极限定理**，可使用自助法/自展法（bootstrap）即放回抽样进行样本的抽取，利用强大的计算能力**模拟统计量的抽样分布**，得到最佳估计

1. 抽样
    * 使用函数np.random.choice(ndarray, size=n)从总样本ndarray中抽取数量为n的元素作为样本。
    * 使用方法df.sample(n, replace=True)进行有放回抽样
2. 计算置信区间
    * 使用函数 `np.percentile(ndarray, q)` 计算一个多维数组的**任意百分比分位数**（此处的百分位是从小到大排列）

```python
a = range(1,101)
#求取a数列第90%分位的数值
np.percentile(a, 90)

# 计算 boot_means 95%的置信区间（左右各删除2.5%的区域）
np.percentile(boot_means, 2.5), np.percentile(boot_means, 97.5)
```

:hammer:

```shell
90.10000000000001

(66.00553304554542, 67.597304583948613)
```
注意：描述所构建的置信区间是需要规范表述
* 置信度的准确值
* 该置信区间所采集的参数

参考：[numpy库 `np.percentile` 详解](https://blog.csdn.net/brucewong0516/article/details/80205422)

## 置信区间的应用
* 通过建立**均数差**置信区间，挑选两个方案中较优的方案，如A/B测试（或称为分离测试）（不直接使用两个点估计值比较，可避免由于样本随机性而产生这些差别的唯一原因）
* 置信区间采用综合方法，基于数据得出结论，因为这些测试旨在理解总体的参数 (即总体数值的集合)。

另外，机器学习采用个别方法得出结论，因为通过每个单独数据点预测结果。

## 相关术语
* 样本容量 sample size
* 置信度（如 `95%` 或 `99%`） cofidence level
* 误差范围 margin of error (MOE)：置信区间宽度的一半（可通过样本估计值对误差范围的加减，获得置信区间的最终结果）
* 置信宽度 confidence interval width：置信区间上限与下限的差异